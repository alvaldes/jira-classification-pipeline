# JIRA Classification Pipeline

> ğŸ¯ Pipeline de Machine Learning para PredicciÃ³n de Defectos en Software usando Datasets JIRA

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-Latest-green.svg)](https://scikit-learn.org)

## ğŸ“‹ DescripciÃ³n del Proyecto

Este repositorio implementa un pipeline completo de Machine Learning para la **predicciÃ³n de defectos en software** utilizando datasets de proyectos reales extraÃ­dos de JIRA. El proyecto se enfoca en resolver problemas de **clasificaciÃ³n desbalanceada** mediante la implementaciÃ³n del mÃ©todo **HCBOU** (Hybrid Cluster-Based Oversampling and Undersampling) junto con tÃ©cnicas como **CSBBOST** y **SMOTE**.

### ğŸ¯ Objetivos Principales

- Predecir defectos de software usando mÃ©tricas de cÃ³digo y proceso
- Manejar datasets desbalanceados mediante tÃ©cnicas de balanceo hÃ­bridas
- Comparar diferentes algoritmos de clasificaciÃ³n (Random Forest, AdaBoost)
- Evaluar el rendimiento con mÃºltiples mÃ©tricas especializadas en datos desbalanceados

## ğŸ—ï¸ Arquitectura del Pipeline

```mermaid
flowchart LR
    A[Conjuntos de datos de Jira] --> B[Conjunto de datos de entrenamiento 80%]
    A --> C[Conjunto de datos de prueba 20%]

    B --> D[NormalizaciÃ³n StandardScaler]
    D --> E[Balanceo de clases HCBOU, CSBBOST, SMOTE]
    E --> F[Conjunto de datos de entrenamiento balanceados]

    F --> G[SelecciÃ³n de caracterÃ­sticas Decision Tree, CatBoost]
    G --> H[ClasificaciÃ³n]

    C --> I[NormalizaciÃ³n StandardScaler]
    I --> J[Balanceo de clases HCBOU, CSBBOST, SMOTE]

    H --> K[EvaluaciÃ³n Final]
    J --> K
```

## ğŸ“ Estructura del Repositorio

```
jira-classification-pipeline/
â”œâ”€â”€ ğŸ“Š datasets/              # Datasets de proyectos de software
â”‚   â”œâ”€â”€ activemq-5.0.0.csv
â”‚   â”œâ”€â”€ groovy-1_6_BETA_1.csv
â”‚   â”œâ”€â”€ hbase-0.94.0.csv
â”‚   â”œâ”€â”€ derby-10.5.1.1.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ”§ preprocessing/         # Notebooks de preprocesamiento
â”‚   â”œâ”€â”€ groovy-1_5_7.ipynb
â”‚   â”œâ”€â”€ hbase-0.94.0.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ âš–ï¸ class-blance/         # ImplementaciÃ³n de balanceo HCBOU
â”‚   â”œâ”€â”€ activemq-5.0.0.ipynb
â”‚   â””â”€â”€ activemq-5.0.0-hcbou.ipynb
â”œâ”€â”€ ğŸ› ï¸ utils/                # CÃ³digo de utilidades y anÃ¡lisis
â”‚   â””â”€â”€ HCBOU Code.ipynb
â”œâ”€â”€ ğŸ“š papers/               # Referencias acadÃ©micas
â”‚   â”œâ”€â”€ s41598-024-84786-2.pdf
â”‚   â””â”€â”€ yatish2019mining.pdf
â””â”€â”€ ğŸ“– docs/                 # DocumentaciÃ³n del proyecto
    â”œâ”€â”€ README.md
    â””â”€â”€ CLAUDE.md
```

## ğŸ”§ TecnologÃ­as y Dependencias

### LibrerÃ­as Principales

```python
import pandas as pd                    # ManipulaciÃ³n de datos
import numpy as np                     # Operaciones numÃ©ricas
import scikit-learn                    # Machine Learning
import imblearn                        # TÃ©cnicas de balanceo
import matplotlib.pyplot as plt        # VisualizaciÃ³n
import seaborn as sns                  # VisualizaciÃ³n avanzada
```

### Algoritmos Implementados

- **ğŸ¯ Balanceo de Clases:**
  - HCBOU (Hybrid Cluster-Based Oversampling and Undersampling)
  - SMOTE (Synthetic Minority Oversampling Technique)
  - ClusterCentroids (Undersampling basado en clustering)

- **ğŸ§  Clasificadores:**
  - Random Forest
  - AdaBoost
  - Gradient Boosting
  - OneVsRest / OneVsOne strategies

- **ğŸ“ MÃ©tricas de EvaluaciÃ³n:**
  - ROC-AUC Score
  - F1-Score
  - Geometric Mean
  - Cohen's Kappa
  - Precision/Recall

## ğŸš€ ConfiguraciÃ³n e InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/jira-classification-pipeline.git
cd jira-classification-pipeline
```

### 2. Instalar Dependencias

```bash
# Instalar dependencias principales
pip install pandas numpy scikit-learn imbalanced-learn
pip install matplotlib seaborn jupyter
pip install openpyxl xlrd

# Para clustering avanzado
pip install scikit-fuzzy kneed
```

### 3. Ejecutar Jupyter Notebook

```bash
jupyter notebook
```

## ğŸ“Š Uso del Pipeline

### 1. Cargar y Preparar Datos

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Cargar dataset
df = pd.read_csv('datasets/activemq-5.0.0.csv')

# Preparar caracterÃ­sticas y target
X = df.drop(columns=['RealBug', 'HeuBug', 'HeuBugCount', 'RealBugCount'])
y = df['RealBug']

# DivisiÃ³n train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

### 2. Aplicar NormalizaciÃ³n

```python
# Normalizar caracterÃ­sticas numÃ©ricas
scaler = StandardScaler()
X_train_numeric = X_train.select_dtypes(include=['float64', 'int64'])
X_train_scaled = scaler.fit_transform(X_train_numeric)
```

### 3. Balanceo de Clases con HCBOU

```python
# ConfiguraciÃ³n HCBOU
maxclusterMaj = 8      # Clusters para clase mayoritaria
maxclusterMin = 6      # Clusters para clase minoritaria
KSMOTE = 3            # Vecinos para SMOTE
MinClusterObs = 5     # Observaciones mÃ­nimas por cluster

# Aplicar HCBOU (ver utils/HCBOU Code.ipynb para implementaciÃ³n completa)
```

### 4. Entrenamiento y EvaluaciÃ³n

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import classification_report

# Entrenar modelo
clf = OneVsRestClassifier(RandomForestClassifier(random_state=42))
clf.fit(X_train_balanced, y_train_balanced)

# EvaluaciÃ³n
y_pred = clf.predict(X_test_scaled)
print(classification_report(y_test, y_pred))
```

## ğŸ“ˆ Datasets Disponibles

| Proyecto | Archivos | Defectos | Ratio | DescripciÃ³n |
|----------|----------|----------|-------|-------------|
| ActiveMQ 5.0.0 | 1,884 | 293 | 15.5% | Message broker Java |
| Groovy 1.6 | 757 | 26 | 3.4% | Lenguaje dinÃ¡mico JVM |
| HBase 0.94.0 | - | - | - | Base de datos NoSQL |
| Derby 10.5.1.1 | - | - | - | Base de datos Java |

### MÃ©tricas Incluidas

- **MÃ©tricas de CÃ³digo:** LOC, Complejidad CiclomÃ¡tica, MÃ©todos, Clases
- **MÃ©tricas de Proceso:** Commits, Desarrolladores, LÃ­neas aÃ±adidas/eliminadas
- **Target:** RealBug (boolean) - Indica si el archivo contiene defectos

## ğŸ§ª Resultados y EvaluaciÃ³n

### MÃ©tricas de EvaluaciÃ³n Implementadas

```python
# MÃ©tricas para datos desbalanceados
- Geometric Mean Score
- ROC-AUC Multiclass
- Cohen's Kappa Score
- F1-Score Macro/Weighted
- Hamming Loss
```

### Estrategias de ValidaciÃ³n

- **Train/Test Split:** 80/20
- **Cross-Validation:** K-Fold para validaciÃ³n robusta
- **ComparaciÃ³n de MÃ©todos:** Original vs HCBOU vs SMOTE vs ClusterCentroids

## ğŸ“š Referencias AcadÃ©micas

Este proyecto se basa en investigaciÃ³n acadÃ©mica en predicciÃ³n de defectos de software:

1. **HCBOU Method:** Hybrid Cluster-Based Oversampling and Undersampling
2. **Software Defect Prediction:** Machine Learning approaches
3. **Imbalanced Learning:** Techniques for skewed datasets

Ver carpeta `papers/` para referencias completas.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Para contribuir:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add: Amazing Feature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ“§ Contacto

- **Proyecto:** PredicciÃ³n de errores en ISW
- **Universidad:** MIS UTM - 3er Semestre
- **Repositorio:** [GitHub](https://github.com/tu-usuario/jira-classification-pipeline)

---

â­ Si este proyecto te resulta Ãºtil, Â¡no olvides darle una estrella!